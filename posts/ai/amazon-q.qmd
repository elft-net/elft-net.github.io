
---
title: "The Q-Factor"
author: "Peter Mostert"
date: "2024-09-25"
image: "ai-amazon-q.jpg"
categories: [amazon, aws, ai]
---

While our development pallet grows more generative and creative the providers got stuck into legacy branding patterns. The twitter guy is into X, microSoft brands all the things Copilot and Amazon is into Q.

Off all AI-providers Amazon Q provided the highest barrier of entry by far and still lacks support for the tools I generally use. But putting my bias aside I should be able to get something going so let's see whats the Amazon-Q interface has to offer. 

Don't let the quantity of this post scare you away. Most of the content got generated by Q, has been added while it has relevancy but can be easily skimmed over!

**Amazon Q for command line**

The Amazon docs portal provides a [document](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-getting-started-installing.html) describing how to get things going if using macOS. 

Besides a mac this requires a subscription for Builder ID which seems to be free. After install a `q` command is added to the command pallet. At first sight the most appealing options are the CLI-completions and the CLI-chatbot. Lets play a bit with the latter.

**The Q-bot**

Lets first figure out if Q "knows" about Terraform which is a Third Party Tool (their native IaC tool is called CloudFormation) and Talos (available on AWS as a community AMI).

[mos@chap ~]$ q chat

Hi, I'm Amazon Q. I can answer questions about your shell and CLI tools!
You can include additional context by adding the following to your prompt:

@history to pass your shell history
@git to pass information about your current git repository
@env to pass your shell environment

> can you give me some advice on terraform code in AWS

Certainly! I'd be happy to provide some advice on using Terraform with AWS. Here are some best practices and
tips to help you write effective and maintainable Terraform code for AWS: [1]

1. Use modules: Organize your code into reusable modules to improve maintainability and promote code reuse
across different projects or environments.

2. Follow a consistent naming convention: Use a consistent naming scheme for your resources, variables, and
outputs to improve readability and maintainability.

3. Use remote state storage: Store your Terraform state files in a remote backend like S3 with DynamoDB for
state locking. This enables collaboration and helps prevent conflicts. [2]

4. Implement proper state management: Use workspaces or separate state files for different environments (dev,
staging, prod) to keep your infrastructure isolated.

5. Use variables and locals: Leverage variables for values that might change and locals for computed values or
to improve readability.

6. Implement proper version control: Use version control systems like Git to manage your Terraform code and
track changes over time. [3]

7. Use data sources: Utilize data sources to fetch existing AWS resources instead of hardcoding values.

8. Implement proper tagging: Use tags for your AWS resources to improve organization, cost allocation, and
resource management.

9. Use terraform-docs: Generate documentation automatically for your Terraform modules using tools like
terraform-docs.

10. Implement proper error handling: Use the count parameter or for_each to handle conditional resource
creation and avoid errors.

11. Use the AWS provider alias: When working with multiple AWS accounts or regions, use provider aliases to
manage resources across different environments.

12. Implement proper security practices: Use IAM roles and policies to manage access, and avoid hardcoding
sensitive information in your Terraform code.

Here's a simple example that demonstrates some of these practices:

```hcl
# Define the AWS provider
provider "aws" {
  region = var.aws_region
}

# Use a module for creating an EC2 instance
module "ec2_instance" {
  source  = "terraform-aws-modules/ec2-instance/aws"
  version = "~> 3.0"

  name = "my-ec2-instance"

  ami                    = data.aws_ami.amazon_linux_2.id
  instance_type          = var.instance_type
  key_name               = var.key_name
  monitoring             = true
  vpc_security_group_ids = [aws_security_group.allow_ssh.id]
  subnet_id              = var.subnet_id

  tags = {
    Terraform   = "true"
    Environment = var.environment
  }
}

# Use a data source to fetch the latest Amazon Linux 2 AMI
data "aws_ami" "amazon_linux_2" {
  most_recent = true
  owners      = ["amazon"]

  filter {
    name   = "name"
    values = ["amzn2-ami-hvm-*-x86_64-gp2"]
  }
}

# Create a security group
resource "aws_security_group" "allow_ssh" {
  name        = "allow_ssh"
  description = "Allow SSH inbound traffic"
  vpc_id      = var.vpc_id

  ingress {
    description = "SSH from VPC"
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = [var.vpc_cidr]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name = "allow_ssh"
  }
}

# Define variables
variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-west-2"
}

variable "instance_type" {
  description = "EC2 instance type"
  type        = string
  default     = "t2.micro"
}

variable "key_name" {
  description = "Key pair name"
  type        = string
}

variable "subnet_id" {
  description = "Subnet ID"
  type        = string
}

variable "vpc_id" {
  description = "VPC ID"
  type        = string
}

variable "vpc_cidr" {
  description = "VPC CIDR block"
  type        = string
}

variable "environment" {
  description = "Environment name"
  type        = string
  default     = "dev"
}

# Output the instance ID
output "instance_id" {
  description = "ID of the EC2 instance"
  value       = module.ec2_instance.id
}
```
This example demonstrates the use of modules, data sources, variables, and proper resource organization.
Remember to adapt this code to your specific needs and always follow AWS best practices for security and
resource management.

1 https://aws.amazon.com/about-aws/whats-new/2023/11/amazon-codecatalyst-supports-terraform/
2 https://repost.aws/articles/AR1Iq4DrJtThK4K2svXyuF3w/using-codecatalyst-to-deploy-terraform-infrastructure-as-code
3 https://docs.aws.amazon.com/prescriptive-guidance/latest/getting-started-terraform/introduction.html

Ooempf, that does not disappoint. Now let's try somethinig more specific.

**IaC for an Instance running Talos**

> I would like to have the terraform code that provides me with a talos image running the control plane as well as the worker plane for a medium developer setup. The terraform code should provide an EC2 resource with sufficient capacity to run a medium developer instance. Initially it can run in the default vpc. Can you provide
the terraform code needed to provision this ?

Certainly! I can provide you with Terraform code to set up an EC2 instance running a Talos image for both the
control plane and worker plane in a medium developer setup. We'll use the default VPC for simplicity. Here's
the Terraform code to achieve this:

```hcl
provider "aws" {
  region = "eu-central-1"  # Change this to your preferred region
}

data "aws_vpc" "default" {
  default = true
}

data "aws_subnets" "default" {
  filter {
    name   = "vpc-id"
    values = [data.aws_vpc.default.id]
  }
}

resource "aws_security_group" "talos_sg" {
  name        = "talos-security-group"
  description = "Security group for Talos Kubernetes cluster"
  vpc_id      = data.aws_vpc.default.id

  # Allow all outbound traffic
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  # Allow inbound SSH access
  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  # Allow Kubernetes API server
  ingress {
    from_port   = 6443
    to_port     = 6443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  # Allow Talos API
  ingress {
    from_port   = 50000
    to_port     = 50001
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

data "aws_ami" "talos" {
  most_recent = true
  owners      = ["540036508848"] # Talos Systems' AWS account ID

  filter {
    name   = "name"
    values = ["talos-amd64-*"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }
}

resource "aws_instance" "talos_node" {
  ami           = data.aws_ami.talos.id
  instance_type = "t3.medium"  # Adjust as needed for your "medium developer setup"

  vpc_security_group_ids = [aws_security_group.talos_sg.id]
  subnet_id              = data.aws_subnets.default.ids[0]

  root_block_device {
    volume_type = "gp3"
    volume_size = 50  # Adjust as needed
  }

  tags = {
    Name = "talos-node"
  }

  user_data = <<-EOF
              {
                "version": "v1alpha1",
                "persist": true,
                "machine": {
                  "type": "controlplane",
                  "token": "${random_password.talos_token.result}",
                  "ca": {
                    "crt": "${base64encode(tls_self_signed_cert.talos_ca.cert_pem)}",
                    "key": "${base64encode(tls_private_key.talos_ca.private_key_pem)}"
                  }
                },
                "cluster": {
                  "id": "${random_uuid.cluster_id.result}",
                  "secret": "${random_password.cluster_secret.result}",
                  "controlPlane": {
                    "endpoint": "https://${aws_instance.talos_node.public_ip}:6443"
                  }
                }
              }
              EOF
}

resource "random_password" "talos_token" {
  length  = 32
  special = false
}

resource "random_uuid" "cluster_id" {}

resource "random_password" "cluster_secret" {
  length  = 32
  special = false
}

resource "tls_private_key" "talos_ca" {
  algorithm = "RSA"
  rsa_bits  = 4096
}

resource "tls_self_signed_cert" "talos_ca" {
  private_key_pem = tls_private_key.talos_ca.private_key_pem

  subject {
    common_name = "talos"
  }

  validity_period_hours = 8760  # 1 year

  allowed_uses = [
    "key_encipherment",
    "digital_signature",
    "server_auth",
    "client_auth",
  ]

  is_ca_certificate = true
}

output "talos_node_public_ip" {
  value = aws_instance.talos_node.public_ip
}

output "talos_node_private_ip" {
  value = aws_instance.talos_node.private_ip
}

```
This Terraform code does the following:

1. Sets up the AWS provider (you'll need to configure your AWS credentials).
2. Uses the default VPC and subnet.
3. Creates a security group allowing necessary inbound traffic for Talos and Kubernetes.
4. Finds the latest Talos AMI.
5. Creates an EC2 instance using the Talos AMI with a t3.medium instance type (adjust as needed).
6. Generates necessary tokens, IDs, and certificates for Talos configuration.
7. Provides the Talos configuration as user data to the EC2 instance.

To use this code:

1. Save it to a file with a .tf extension (e.g., talos_setup.tf).
2. Run terraform init to initialize the Terraform working directory. [1]
3. Run terraform plan to see the execution plan.
4. Run terraform apply to create the resources.

After applying, you'll get the public and private IP addresses of the Talos node as outputs.

Note that this setup creates a single node acting as both control plane and worker. For a production
environment, you'd want to separate these and create multiple nodes. Also, remember to secure your cluster
properly, as this example opens some ports to 0.0.0.0/0 for simplicity.

To fully set up and interact with your Talos cluster, you'll need to install the Talos CLI (talosctl) on your
local machine and perform additional configuration steps. Refer to the Talos documentation for post-
installation steps and how to interact with your new cluster.

1 https://repost.aws/articles/ARcZH31DCIS-K3Ivns0ey-dA/automating-ec2-instance-naming-with-terraform-and-user-data-a-solution-for-dynamic-environments

>

**Good Practices**

None of the good practices of the generic example got implemented in the specific code. Moreover port 22 is opened for the public while Talos does not require this afaik.


Had to do some fiddling for to get the correct ami selected and removed a self reference to the end-point but then the plan seemd to come together.

```
Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

random_uuid.cluster_id: Creating...
tls_private_key.talos_ca: Creating...
random_uuid.cluster_id: Creation complete after 0s [id=6352c2f2-f216-1659-eb51-d019287cb7bc]
random_password.talos_token: Creating...
random_password.cluster_secret: Creating...
random_password.talos_token: Creation complete after 0s [id=none]
random_password.cluster_secret: Creation complete after 0s [id=none]
aws_security_group.talos_sg: Creating...
tls_private_key.talos_ca: Creation complete after 2s [id=e6c78d34a473c3e3498202797146adc7e644d339]
tls_self_signed_cert.talos_ca: Creating...
tls_self_signed_cert.talos_ca: Creation complete after 0s [id=160873380053405108687366549035503198069]
aws_security_group.talos_sg: Creation complete after 2s [id=sg-041c4f1a231aaa943]
aws_instance.talos_node: Creating...
aws_instance.talos_node: Still creating... [10s elapsed]
aws_instance.talos_node: Creation complete after 13s [id=i-00c4cb23e04838b0f]

Apply complete! Resources: 7 added, 0 changed, 0 destroyed.

Outputs:

talos_node_private_ip = "172.31.7.6"
talos_node_public_ip = "3.69.46.111"
[mos@chap ~/…/play/devops-directive-terraform-course/10-aws-talos]$
```

In theory this should enable us to setup the Talos cluster but trying to do so returns:

```html
Unable to connect

An error occurred during a connection to ec2-3-69-46-111.eu-central-1.compute.amazonaws.com:6443.

    The site could be temporarily unavailable or too busy. Try again in a few moments.
    If you are unable to load any pages, check your computer’s network connection.
    If your computer or network is protected by a firewall or proxy, make sure that Firefox is permitted to access the web.
```
Not a good sign . . . trying to bootstrap the Talos node anyway caused some further havoc:
```bash
[mos@chap ~/…/play/devops-directive-terraform-course/10-aws-talos]$ talosctl gen config talos-cluster https://3.69.46.111:6443
generating PKI and tokens
Created /Users/mos/Repo/play/devops-directive-terraform-course/10-aws-talos/controlplane.yaml
Created /Users/mos/Repo/play/devops-directive-terraform-course/10-aws-talos/worker.yaml
Created /Users/mos/Repo/play/devops-directive-terraform-course/10-aws-talos/talosconfig
[mos@chap ~/…/play/devops-directive-terraform-course/10-aws-talos]$ talosctl apply-config --insecure -n 3.69.46.111 --file controlplane.yaml                                                                                      
error applying new configuration: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing: dial tcp 3.69.46.111:50000: connect: connection refused"
```

**Next Steps**

Referring to the [Talos Documentation](https://www.talos.dev/v1.8/talos-guides/install/cloud-platforms/aws/) for how this should be done properly.

Bluntly following Q got something running up in the AWS Clouds. While the instance seemed to be properly running the talosctl service could not connect for some reason. This project was started at a pinch, not prepared for whatsoever so I might have picked an outdated image or try to use a workflow that is not applicable for this AMI . . . .

The Q-generated Terraform template is still a far stretch from what is described in the Talos docs. On the other hand that's what I asked for, a developer instance running Talos so that's what I got. 

It would have been nice if it would have worked though. Might just save that for another rainy day.

What is left for now is `tf destroy` to take things back down again.
